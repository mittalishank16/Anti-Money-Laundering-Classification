{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f69b4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from pathlib import Path\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    recall_score,\n",
    "    fbeta_score, accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', None)     # Show all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f5a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import load\n",
    "\n",
    "X_train, y_train, X_test, y_test = joblib.load('smote_dataset_splits.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for XGBClassifier.\"\"\"\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1, 10), # Useful even with SMOTE\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"logloss\"\n",
    "    }\n",
    "\n",
    "    # Start a nested MLflow run for each trial\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Classification Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        f2 = fbeta_score(y_test, y_pred, beta=2, pos_label=1)\n",
    "\n",
    "        # Log to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": acc,\n",
    "            \"f1_score\": f1,\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"pr_auc\": pr_auc,\n",
    "            \"f2_score\": f2\n",
    "        })\n",
    "\n",
    "    # We maximize F1-score because of the fraud imbalance\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36680671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-28 15:46:56,724] A new study created in memory with name: no-name-b98aa233-bcd4-453b-b1ea-98c1a2113e36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-28 15:46:57,549] Trial 0 finished with value: 0.41963509991311904 and parameters: {'n_estimators': 673, 'max_depth': 8, 'learning_rate': 0.06367818016075064, 'subsample': 0.6515684031163799, 'colsample_bytree': 0.9500054096484398, 'min_child_weight': 7, 'gamma': 1.8099738884228622, 'reg_alpha': 0.16816672962224202, 'reg_lambda': 0.015174400123502999, 'scale_pos_weight': 8.400634833603963}. Best is trial 0 with value: 0.41963509991311904.\n",
      "[I 2026-01-28 15:46:58,160] Trial 1 finished with value: 0.4015594541910331 and parameters: {'n_estimators': 809, 'max_depth': 3, 'learning_rate': 0.012863738386500461, 'subsample': 0.6294882925188217, 'colsample_bytree': 0.6432320388600985, 'min_child_weight': 7, 'gamma': 1.5107480999108114, 'reg_alpha': 2.6131806647170496e-07, 'reg_lambda': 3.704790550472849e-08, 'scale_pos_weight': 9.601114267621666}. Best is trial 0 with value: 0.41963509991311904.\n",
      "[I 2026-01-28 15:46:58,725] Trial 2 finished with value: 0.46270423869287236 and parameters: {'n_estimators': 765, 'max_depth': 9, 'learning_rate': 0.03597138580265416, 'subsample': 0.908301412186753, 'colsample_bytree': 0.7245278626046269, 'min_child_weight': 5, 'gamma': 2.050854836083571, 'reg_alpha': 1.0506828775360605e-06, 'reg_lambda': 1.1926417410447034e-08, 'scale_pos_weight': 1.154625875275456}. Best is trial 2 with value: 0.46270423869287236.\n",
      "[I 2026-01-28 15:46:59,122] Trial 3 finished with value: 0.48580925594477115 and parameters: {'n_estimators': 322, 'max_depth': 8, 'learning_rate': 0.17677146278362665, 'subsample': 0.8055443543150015, 'colsample_bytree': 0.530502671961943, 'min_child_weight': 3, 'gamma': 0.6676015097598342, 'reg_alpha': 2.9534945609547678e-08, 'reg_lambda': 4.974565791965434e-07, 'scale_pos_weight': 1.9370168850375515}. Best is trial 3 with value: 0.48580925594477115.\n",
      "[I 2026-01-28 15:46:59,639] Trial 4 finished with value: 0.4994612068965517 and parameters: {'n_estimators': 412, 'max_depth': 7, 'learning_rate': 0.10434744094538664, 'subsample': 0.5534106968640584, 'colsample_bytree': 0.7153895993455861, 'min_child_weight': 3, 'gamma': 0.37473582812157236, 'reg_alpha': 0.0006713461653557856, 'reg_lambda': 0.0651701879389847, 'scale_pos_weight': 1.585057787173384}. Best is trial 4 with value: 0.4994612068965517.\n",
      "[I 2026-01-28 15:47:00,618] Trial 5 finished with value: 0.44840351689032854 and parameters: {'n_estimators': 792, 'max_depth': 9, 'learning_rate': 0.03763825781516002, 'subsample': 0.5810276746270993, 'colsample_bytree': 0.8614262511560613, 'min_child_weight': 7, 'gamma': 2.3941091963188694, 'reg_alpha': 0.0004413215014586923, 'reg_lambda': 2.6963324372405902e-08, 'scale_pos_weight': 5.734606049050903}. Best is trial 4 with value: 0.4994612068965517.\n",
      "[I 2026-01-28 15:47:01,354] Trial 6 finished with value: 0.41517948717948716 and parameters: {'n_estimators': 876, 'max_depth': 9, 'learning_rate': 0.030200863609168835, 'subsample': 0.8169636274625116, 'colsample_bytree': 0.7959499369260477, 'min_child_weight': 3, 'gamma': 2.414657382075549, 'reg_alpha': 0.01566999238957375, 'reg_lambda': 0.0005509163254129794, 'scale_pos_weight': 1.9895675105733333}. Best is trial 4 with value: 0.4994612068965517.\n",
      "[I 2026-01-28 15:47:02,423] Trial 7 finished with value: 0.4346305203323131 and parameters: {'n_estimators': 845, 'max_depth': 8, 'learning_rate': 0.011579062582099663, 'subsample': 0.6165378342603797, 'colsample_bytree': 0.7453778774803392, 'min_child_weight': 6, 'gamma': 1.9492419256974052, 'reg_alpha': 0.19612275487497438, 'reg_lambda': 0.00018161884410203386, 'scale_pos_weight': 9.630033191478482}. Best is trial 4 with value: 0.4994612068965517.\n",
      "[I 2026-01-28 15:47:03,297] Trial 8 finished with value: 0.4286020124170413 and parameters: {'n_estimators': 959, 'max_depth': 5, 'learning_rate': 0.030995027137452606, 'subsample': 0.6428487940339322, 'colsample_bytree': 0.7722888358109589, 'min_child_weight': 2, 'gamma': 2.7622337296684214, 'reg_alpha': 2.723256996663113e-08, 'reg_lambda': 0.013261799357728418, 'scale_pos_weight': 8.608082522179249}. Best is trial 4 with value: 0.4994612068965517.\n",
      "[I 2026-01-28 15:47:04,434] Trial 9 finished with value: 0.41013628620102216 and parameters: {'n_estimators': 892, 'max_depth': 8, 'learning_rate': 0.08060144892390364, 'subsample': 0.6827551551315607, 'colsample_bytree': 0.900652012106709, 'min_child_weight': 3, 'gamma': 0.6555391232981334, 'reg_alpha': 0.04346593198100061, 'reg_lambda': 6.558077706302746e-05, 'scale_pos_weight': 9.353145279030398}. Best is trial 4 with value: 0.4994612068965517.\n",
      "[I 2026-01-28 15:47:04,807] Trial 10 finished with value: 0.5065107626893436 and parameters: {'n_estimators': 407, 'max_depth': 6, 'learning_rate': 0.2618334741789985, 'subsample': 0.505834406353306, 'colsample_bytree': 0.6127855365718692, 'min_child_weight': 10, 'gamma': 4.24376805683629, 'reg_alpha': 0.00016735055353851895, 'reg_lambda': 6.950488982830555, 'scale_pos_weight': 4.143270205332353}. Best is trial 10 with value: 0.5065107626893436.\n",
      "[I 2026-01-28 15:47:05,183] Trial 11 finished with value: 0.4929251350656033 and parameters: {'n_estimators': 406, 'max_depth': 6, 'learning_rate': 0.2293065584825668, 'subsample': 0.5034911941081335, 'colsample_bytree': 0.6047844653752456, 'min_child_weight': 10, 'gamma': 4.467590397759821, 'reg_alpha': 4.2405572849342314e-05, 'reg_lambda': 7.777045345203768, 'scale_pos_weight': 3.855334289168609}. Best is trial 10 with value: 0.5065107626893436.\n",
      "[I 2026-01-28 15:47:05,614] Trial 12 finished with value: 0.49921752738654146 and parameters: {'n_estimators': 487, 'max_depth': 5, 'learning_rate': 0.1181554942744331, 'subsample': 0.5098234816575343, 'colsample_bytree': 0.6453699364491379, 'min_child_weight': 10, 'gamma': 4.905835105676022, 'reg_alpha': 0.00029155251474930984, 'reg_lambda': 7.296808419019314, 'scale_pos_weight': 4.064223078924951}. Best is trial 10 with value: 0.5065107626893436.\n",
      "[I 2026-01-28 15:47:05,806] Trial 13 finished with value: 0.44877830082941045 and parameters: {'n_estimators': 207, 'max_depth': 6, 'learning_rate': 0.28173725526167515, 'subsample': 0.9942133055090414, 'colsample_bytree': 0.5242593564090453, 'min_child_weight': 5, 'gamma': 3.5720067537907565, 'reg_alpha': 1.2601389577276268e-05, 'reg_lambda': 0.15271520743818842, 'scale_pos_weight': 3.702556480663472}. Best is trial 10 with value: 0.5065107626893436.\n",
      "[I 2026-01-28 15:47:06,264] Trial 14 finished with value: 0.44733887267011 and parameters: {'n_estimators': 537, 'max_depth': 4, 'learning_rate': 0.11940213632292158, 'subsample': 0.7426368594076728, 'colsample_bytree': 0.6839699045823213, 'min_child_weight': 1, 'gamma': 3.724045567443589, 'reg_alpha': 0.0028866258810411453, 'reg_lambda': 0.388913544432672, 'scale_pos_weight': 6.045743759024905}. Best is trial 10 with value: 0.5065107626893436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params: {'n_estimators': 407, 'max_depth': 6, 'learning_rate': 0.2618334741789985, 'subsample': 0.505834406353306, 'colsample_bytree': 0.6127855365718692, 'min_child_weight': 10, 'gamma': 4.24376805683629, 'reg_alpha': 0.00016735055353851895, 'reg_lambda': 6.950488982830555, 'scale_pos_weight': 4.143270205332353}\n",
      "\n",
      "Training final model with best parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/28 15:47:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Model Performance ---\n",
      "final_accuracy: 0.8370\n",
      "final_f1: 0.5065\n",
      "final_recall: 0.9208\n",
      "final_roc_auc: 0.9484\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.90     10355\n",
      "           1       0.35      0.92      0.51      1035\n",
      "\n",
      "    accuracy                           0.84     11390\n",
      "   macro avg       0.67      0.87      0.70     11390\n",
      "weighted avg       0.93      0.84      0.87     11390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup MLflow Tracking\n",
    "# Ensure this path matches your local project structure\n",
    "mlflow.set_tracking_uri(r\"file:///C:/Users/user/Desktop/ML & DL projects/Anti- Money Laundering classification/mlruns\")\n",
    "mlflow.set_experiment(\"AML_XGBoost_Optuna_Notebook\")\n",
    "\n",
    "# 2. Run the Optuna Study\n",
    "with mlflow.start_run(run_name=\"XGB_Hyperparameter_Tuning\"):\n",
    "    print(\"Starting optimization...\")\n",
    "    \n",
    "    # We use direction=\"maximize\" because we want to maximize the F1-score\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=15)\n",
    "    \n",
    "    # 3. Retrieve Best Results\n",
    "    print(\"\\nBest params:\", study.best_trial.params)\n",
    "    best_params = study.best_trial.params\n",
    "    \n",
    "    # 4. Train Final Model with Best Parameters\n",
    "    print(\"\\nTraining final model with best parameters...\")\n",
    "    best_model = XGBClassifier(**best_params, random_state=42, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 5. Final Evaluation\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    metrics = {\n",
    "        \"final_accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"final_f1\": f1_score(y_test, y_pred),\n",
    "        \"final_recall\": recall_score(y_test, y_pred),\n",
    "        \"final_roc_auc\": roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "    \n",
    "    # 6. Log Best Model and Metrics to the Parent Run\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.xgboost.log_model(best_model, artifact_path=\"best_model\")\n",
    "    \n",
    "    print(\"\\n--- Final Model Performance ---\")\n",
    "    for name, value in metrics.items():\n",
    "        print(f\"{name}: {value:.4f}\")\n",
    "        \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92dc05f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_xgb_classifier.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model locally for convenience\n",
    "joblib.dump(best_model, \"best_xgb_classifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c736ebb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb99bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
