{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69b4573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    recall_score,\n",
    "    fbeta_score, accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.max_rows', None)     # Show all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f5a786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import load\n",
    "\n",
    "X_train, y_train, X_test, y_test = joblib.load(r'C:\\Users\\user\\Desktop\\ML & DL projects\\Anti- Money Laundering classification\\notebooks\\SMOTEENN_dataset_splits.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d3ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_recall_curve, auc, fbeta_score\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Optuna objective function for CatBoostClassifier.\"\"\"\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 200, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-8, 10.0, log=True),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-8, 10.0, log=True),\n",
    "        \"od_type\": \"Iter\",  # Overfitting detector\n",
    "        \"od_wait\": 50,      # Stop if no improvement for 50 iterations\n",
    "        \"random_state\": 42,\n",
    "        \"verbose\": False,\n",
    "        \"allow_writing_files\": False\n",
    "    }\n",
    "\n",
    "    # Conditional parameters based on bootstrap_type\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0.0, 10.0)\n",
    "    elif params[\"bootstrap_type\"] in [\"Bernoulli\", \"MVS\"]:\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "\n",
    "    # Start a nested MLflow run for each trial\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Classification Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
    "        pr_auc = auc(recall, precision)\n",
    "        f2 = fbeta_score(y_test, y_pred, beta=2)\n",
    "\n",
    "        # Log to MLflow\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\n",
    "            \"accuracy\": acc,\n",
    "            \"f1_score\": f1,\n",
    "            \"roc_auc\": roc_auc,\n",
    "            \"pr_auc\": pr_auc,\n",
    "            \"f2_score\": f2\n",
    "        })\n",
    "\n",
    "    # Recommended: Return pr_auc or f2 based on our previous analysis\n",
    "    return pr_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36680671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mlflow\\tracking\\_tracking_service\\utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "2026/02/17 16:50:56 INFO mlflow.tracking.fluent: Experiment with name 'AML_CatBoost_Optuna_Notebook' does not exist. Creating a new experiment.\n",
      "[I 2026-02-17 16:50:56,490] A new study created in memory with name: no-name-b8dfb5eb-a6d6-433f-8091-985d733a2078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-17 16:51:07,699] Trial 0 finished with value: 0.7702384830000645 and parameters: {'iterations': 438, 'depth': 10, 'learning_rate': 0.012324042279057047, 'l2_leaf_reg': 0.47489045827988247, 'bootstrap_type': 'MVS', 'random_strength': 0.0005656393941420511, 'subsample': 0.6128901406581626}. Best is trial 0 with value: 0.7702384830000645.\n",
      "[I 2026-02-17 16:51:10,916] Trial 1 finished with value: 0.7191317423314876 and parameters: {'iterations': 580, 'depth': 3, 'learning_rate': 0.11294222453043083, 'l2_leaf_reg': 0.059283001494966445, 'bootstrap_type': 'MVS', 'random_strength': 0.000932900117844709, 'subsample': 0.7571376897132054}. Best is trial 0 with value: 0.7702384830000645.\n",
      "[I 2026-02-17 16:51:13,000] Trial 2 finished with value: 0.7494607287602669 and parameters: {'iterations': 229, 'depth': 8, 'learning_rate': 0.08722905499295759, 'l2_leaf_reg': 1.5802939351370494e-05, 'bootstrap_type': 'MVS', 'random_strength': 6.016015978796285, 'subsample': 0.6645917094352995}. Best is trial 0 with value: 0.7702384830000645.\n",
      "[I 2026-02-17 16:51:35,216] Trial 3 finished with value: 0.7359128887015284 and parameters: {'iterations': 902, 'depth': 10, 'learning_rate': 0.019146597344980074, 'l2_leaf_reg': 3.015642558633543e-06, 'bootstrap_type': 'Bernoulli', 'random_strength': 2.0945914828057884e-08, 'subsample': 0.657707348175778}. Best is trial 0 with value: 0.7702384830000645.\n",
      "[I 2026-02-17 16:51:36,638] Trial 4 finished with value: 0.7459518046800871 and parameters: {'iterations': 213, 'depth': 5, 'learning_rate': 0.015882112889922525, 'l2_leaf_reg': 4.097750851683352, 'bootstrap_type': 'Bernoulli', 'random_strength': 2.4289291550665303e-06, 'subsample': 0.9033150195447877}. Best is trial 0 with value: 0.7702384830000645.\n",
      "[I 2026-02-17 16:51:40,019] Trial 5 finished with value: 0.7683038949236206 and parameters: {'iterations': 569, 'depth': 5, 'learning_rate': 0.010504594201185057, 'l2_leaf_reg': 3.8807530968212176e-08, 'bootstrap_type': 'MVS', 'random_strength': 1.0022017931385491e-06, 'subsample': 0.5882554155506372}. Best is trial 0 with value: 0.7702384830000645.\n",
      "[I 2026-02-17 16:51:43,344] Trial 6 finished with value: 0.7716458091913255 and parameters: {'iterations': 518, 'depth': 6, 'learning_rate': 0.03955868175036121, 'l2_leaf_reg': 0.15154006221759453, 'bootstrap_type': 'Bernoulli', 'random_strength': 7.345636449864422, 'subsample': 0.6164054930404463}. Best is trial 6 with value: 0.7716458091913255.\n",
      "[I 2026-02-17 16:51:48,005] Trial 7 finished with value: 0.5361822752943571 and parameters: {'iterations': 917, 'depth': 4, 'learning_rate': 0.27732533336301896, 'l2_leaf_reg': 1.685407666296006e-05, 'bootstrap_type': 'Bayesian', 'random_strength': 0.00021626037120898824, 'bagging_temperature': 8.91593222590378}. Best is trial 6 with value: 0.7716458091913255.\n",
      "[I 2026-02-17 16:51:49,665] Trial 8 finished with value: 0.6383751160223796 and parameters: {'iterations': 236, 'depth': 6, 'learning_rate': 0.15170274960374064, 'l2_leaf_reg': 0.005288088029192319, 'bootstrap_type': 'Bernoulli', 'random_strength': 5.242045083026609e-06, 'subsample': 0.8724406982459276}. Best is trial 6 with value: 0.7716458091913255.\n",
      "[I 2026-02-17 16:51:59,087] Trial 9 finished with value: 0.7474722370465562 and parameters: {'iterations': 771, 'depth': 9, 'learning_rate': 0.032443628475196676, 'l2_leaf_reg': 0.005054422949792229, 'bootstrap_type': 'Bernoulli', 'random_strength': 9.513799072791692e-06, 'subsample': 0.570174361987537}. Best is trial 6 with value: 0.7716458091913255.\n",
      "[I 2026-02-17 16:52:02,296] Trial 10 finished with value: 0.7774163948065579 and parameters: {'iterations': 415, 'depth': 7, 'learning_rate': 0.04508549829133631, 'l2_leaf_reg': 7.861174385203342, 'bootstrap_type': 'Bayesian', 'random_strength': 6.875754196423715, 'bagging_temperature': 0.4750036028383464}. Best is trial 10 with value: 0.7774163948065579.\n",
      "[I 2026-02-17 16:52:05,596] Trial 11 finished with value: 0.7758431885648771 and parameters: {'iterations': 431, 'depth': 7, 'learning_rate': 0.044034297649688844, 'l2_leaf_reg': 8.148903628103078, 'bootstrap_type': 'Bayesian', 'random_strength': 7.04239974992448, 'bagging_temperature': 0.1922427018727122}. Best is trial 10 with value: 0.7774163948065579.\n",
      "[I 2026-02-17 16:52:09,682] Trial 12 finished with value: 0.7655980710883162 and parameters: {'iterations': 393, 'depth': 8, 'learning_rate': 0.05548687426908209, 'l2_leaf_reg': 7.734751841311064, 'bootstrap_type': 'Bayesian', 'random_strength': 0.1142482368897702, 'bagging_temperature': 0.12770413332914074}. Best is trial 10 with value: 0.7774163948065579.\n",
      "[I 2026-02-17 16:52:12,744] Trial 13 finished with value: 0.7485156789013471 and parameters: {'iterations': 380, 'depth': 7, 'learning_rate': 0.02910818855110716, 'l2_leaf_reg': 0.0017747739169770129, 'bootstrap_type': 'Bayesian', 'random_strength': 0.12146161738289535, 'bagging_temperature': 0.20070982898022383}. Best is trial 10 with value: 0.7774163948065579.\n",
      "[I 2026-02-17 16:52:18,957] Trial 14 finished with value: 0.7524144914562775 and parameters: {'iterations': 707, 'depth': 7, 'learning_rate': 0.06330693667864548, 'l2_leaf_reg': 0.8331655313396183, 'bootstrap_type': 'Bayesian', 'random_strength': 0.08163511118071591, 'bagging_temperature': 2.910230550261548}. Best is trial 10 with value: 0.7774163948065579.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best params: {'iterations': 415, 'depth': 7, 'learning_rate': 0.04508549829133631, 'l2_leaf_reg': 7.861174385203342, 'bootstrap_type': 'Bayesian', 'random_strength': 6.875754196423715, 'bagging_temperature': 0.4750036028383464}\n",
      "\n",
      "Training final model with best parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/17 16:52:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Model Performance ---\n",
      "final_accuracy: 0.8428\n",
      "final_f1: 0.5289\n",
      "final_f2: 0.7277\n",
      "final_pr_auc: 0.7774\n",
      "final_roc_auc: 0.9662\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91     10355\n",
      "           1       0.36      0.97      0.53      1035\n",
      "\n",
      "    accuracy                           0.84     11390\n",
      "   macro avg       0.68      0.90      0.72     11390\n",
      "weighted avg       0.94      0.84      0.87     11390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Setup MLflow Tracking\n",
    "# Updated experiment name to reflect CatBoost\n",
    "mlflow.set_tracking_uri(r\"file:///C:/Users/user/Desktop/ML & DL projects/Anti- Money Laundering classification/mlruns\")\n",
    "mlflow.set_experiment(\"AML_CatBoost_Optuna_Notebook\")\n",
    "\n",
    "# 2. Run the Optuna Study\n",
    "with mlflow.start_run(run_name=\"CatBoost_Hyperparameter_Tuning\"):\n",
    "    print(\"Starting optimization...\")\n",
    "    \n",
    "    # We maximize because our objective returns PR AUC\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=15)\n",
    "    \n",
    "    # 3. Retrieve Best Results\n",
    "    print(\"\\nBest params:\", study.best_trial.params)\n",
    "    best_params = study.best_trial.params\n",
    "    \n",
    "    # 4. Train Final Model with Best Parameters\n",
    "    print(\"\\nTraining final model with best parameters...\")\n",
    "    \n",
    "    # CatBoost needs some static params handled outside of the Optuna trial suggestions\n",
    "    final_params = best_params.copy()\n",
    "    final_params.update({\n",
    "        \"random_state\": 42,\n",
    "        \"verbose\": False,\n",
    "        \"allow_writing_files\": False\n",
    "    })\n",
    "    \n",
    "    best_model = CatBoostClassifier(**final_params)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 5. Final Evaluation\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculating the PR AUC for the final summary\n",
    "    precision_pts, recall_pts, _ = precision_recall_curve(y_test, y_prob)\n",
    "    \n",
    "    metrics = {\n",
    "        \"final_accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"final_f1\": f1_score(y_test, y_pred),\n",
    "        \"final_f2\": fbeta_score(y_test, y_pred, beta=2),\n",
    "        \"final_pr_auc\": auc(recall_pts, precision_pts),\n",
    "        \"final_roc_auc\": roc_auc_score(y_test, y_prob)\n",
    "    }\n",
    "    \n",
    "    # 6. Log Best Model and Metrics to the Parent Run\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.catboost.log_model(best_model, artifact_path=\"best_model\")\n",
    "    \n",
    "    print(\"\\n--- Final Model Performance ---\")\n",
    "    for name, value in metrics.items():\n",
    "        print(f\"{name}: {value:.4f}\")\n",
    "        \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92dc05f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_catboost_classifier.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model locally for convenience\n",
    "joblib.dump(best_model, \"best_catboost_classifier.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954c2290",
   "metadata": {},
   "source": [
    "# Final Model Performance Evaluation: Fraud Detection Context\n",
    "\n",
    "### Summary Metrics\n",
    "| Metric | Value | Interpretation |\n",
    "| :--- | :--- | :--- |\n",
    "| **Recall (Class 1)** | **0.97** | **Elite Performance.** The model captures 97% of all fraud cases. |\n",
    "| **Precision (Class 1)** | **0.36** | **Functional.** 36% of flags are true fraud; implies a high manual review rate. |\n",
    "| **F2-Score** | **0.7277** | **Optimal.** Successfully weights Recall higher than Precision for risk mitigation. |\n",
    "| **PR AUC** | **0.7774** | **Strong.** Indicates high model stability across various decision thresholds. |\n",
    "| **ROC AUC** | **0.9662** | **Excellent.** High degree of separability between Fraud and Non-Fraud. |\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Why these results are \"Good\" for Fraud/Insurance\n",
    "In fraud detection, the **Cost of a False Negative (Missing Fraud)** is significantly higher than the **Cost of a False Positive (Manual Review)**.\n",
    "\n",
    "* **Recall is the Survival Metric:** By achieving **97% Recall**, this system ensures that almost no fraudulent activity leaks through the system. From a risk management perspective, this is the primary goal.\n",
    "* **Precision is a Budget Constraint:** A **36% Precision** is standard for aggressive fraud systems. It means for every 1 true fraud case, you are investigating roughly 2 legitimate cases. While this increases \"operational friction,\" it is a calculated trade-off to prevent catastrophic financial loss.\n",
    "\n",
    "\n",
    "\n",
    "### 2. Detailed Classification Breakdown\n",
    "The report shows a nearly perfect performance on **Class 0 (Non-Fraud)** with a precision of **1.00**, meaning when the model says someone is \"Safe,\" it is almost always correct. This prevents the system from accidentally flagging the entire customer base.\n",
    "\n",
    "### 3. Business Justification\n",
    "If asked to defend this model's 36% precision, the justification is:\n",
    "> *\"In a high-stakes lending or insurance environment, we prioritize **Sensitivity (Recall)** to ensure a 97% capture rate of fraud. We accept a lower Precision as an operational cost, preferring to manually review suspicious cases rather than incur the full cost of undetected fraudulent defaults.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569d11bd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
